{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9999f07a",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca95b6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcb4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Build the Model â€” Multi-Output (owners, players, copiesSold, revenue)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Import Libraries\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib optional (avoid Python 3.13 crash)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MPL = True\n",
    "except Exception as e:\n",
    "    HAS_MPL = False\n",
    "    print(\"Matplotlib unavailable; skipping plots.\\n\", e)\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import tabulate\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b9d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Config\n",
    "# ---------------------------------------------------------------------\n",
    "DATA_PATH = \"games_2020_to_2023_6.csv\"\n",
    "ARTIFACT_DIR = \"./artifacts\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLS = ['owners', 'players', 'copiesSold', 'revenue']\n",
    "\n",
    "# Post-release columns to EXCLUDE from features (leakage)\n",
    "POST_RELEASE = ['wishlists', 'avgPlaytime', 'followers', 'reviews', 'reviewScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9a7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Utils\n",
    "# ---------------------------------------------------------------------\n",
    "def sanitize_column_names(columns):\n",
    "    \"\"\"Keep only letters, numbers, and underscores in column names.\"\"\"\n",
    "    sanitized = []\n",
    "    for col in columns:\n",
    "        clean_col = re.sub(r'[^A-Za-z0-9_]+', '_', str(col))\n",
    "        sanitized.append(clean_col)\n",
    "    return sanitized\n",
    "\n",
    "def build_days_since_release(df):\n",
    "    \"\"\"\n",
    "    Construct days_since_release from the separate date parts:\n",
    "    release_year, release_month, release_day, extract_year, extract_month, extract_day\n",
    "    Does NOT rely on release_date or extract_date columns.\n",
    "    \"\"\"\n",
    "    needed = {'release_year','release_month','release_day','extract_year','extract_month','extract_day'}\n",
    "    if not needed.issubset(df.columns):\n",
    "        raise ValueError(f\"Missing one or more required date part columns: {needed - set(df.columns)}\")\n",
    "\n",
    "    # Build datetime safely\n",
    "    rel = pd.to_datetime(dict(\n",
    "        year=df['release_year'].astype(int),\n",
    "        month=df['release_month'].astype(int),\n",
    "        day=df['release_day'].astype(int)\n",
    "    ), errors='coerce')\n",
    "\n",
    "    ext = pd.to_datetime(dict(\n",
    "        year=df['extract_year'].astype(int),\n",
    "        month=df['extract_month'].astype(int),\n",
    "        day=df['extract_day'].astype(int)\n",
    "    ), errors='coerce')\n",
    "\n",
    "    df['days_since_release'] = (ext - rel).dt.days\n",
    "    return df\n",
    "\n",
    "def basic_feature_engineering(df):\n",
    "    \"\"\"Add a few robust ratios/interactions (safe even if some columns absent).\"\"\"\n",
    "    if 'price' in df.columns and 'achievements' in df.columns:\n",
    "        df['price_per_achievement'] = df['price'] / (df['achievements'] + 1)\n",
    "    if 'wishlists' in df.columns and 'days_since_release' in df.columns:\n",
    "        df['wishlists_per_day'] = df['wishlists'] / (df['days_since_release'] + 1)\n",
    "    if 'price' in df.columns and 'days_since_release' in df.columns:\n",
    "        df['price_x_age'] = df['price'] * np.log1p(df['days_since_release'])\n",
    "    return df\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, targets):\n",
    "    rows = []\n",
    "    for i, t in enumerate(targets):\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i])))\n",
    "        mae  = float(mean_absolute_error(y_true[:, i], y_pred[:, i]))\n",
    "        r2   = float(r2_score(y_true[:, i], y_pred[:, i]))\n",
    "        rows.append({\"target\": t, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fa125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (39194, 56)\n",
      "Clean shape: (39189, 55)\n",
      "Columns: ['price', 'is_free', 'release_year', 'release_month', 'release_day', 'extract_year', 'extract_month', 'extract_day', 'publisherClass_encoded', 'required_age', 'achievements', 'english', 'windows', 'mac', 'linux', 'Single_player', 'Family_Sharing', 'Steam_Achievements', 'Steam_Cloud', 'Full_controller_support'] ...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Load & Clean\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Raw shape:\", df.shape)\n",
    "\n",
    "# Drop obvious non-numeric id/text if present\n",
    "for c in [\"steamid\", \"name\"]:\n",
    "    if c in df.columns:\n",
    "        df.drop(columns=[c], inplace=True)\n",
    "\n",
    "# Build days_since_release from parts (no release_date/extract_date columns needed)\n",
    "df = build_days_since_release(df)\n",
    "\n",
    "# Optional: ensure required_age numeric if present\n",
    "if \"required_age\" in df.columns:\n",
    "    df[\"required_age\"] = df[\"required_age\"].astype(float)\n",
    "\n",
    "# Convert booleans to ints (for safety)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == bool:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "# Sanitize column names for safety in sklearn\n",
    "df.columns = sanitize_column_names(df.columns)\n",
    "\n",
    "# Keep rows with all targets available (cannot train otherwise)\n",
    "df = df.dropna(subset=TARGET_COLS).copy()\n",
    "\n",
    "# Optional: drop rows where all targets are 0 (no signal)\n",
    "df = df[~((df[TARGET_COLS] == 0).all(axis=1))].copy()\n",
    "\n",
    "# Any remaining NaNs -> drop (you can impute if you prefer)\n",
    "df = df.dropna().copy()\n",
    "\n",
    "print(\"Clean shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns)[:20], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f39812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (31351, 46), Test size: (7838, 46)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Train/Test Split with Leakage-Safe X\n",
    "# ---------------------------------------------------------------------\n",
    "# Select numeric columns only for features\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# X: numeric minus targets and minus post-release leakage columns\n",
    "X = df[numeric_cols].drop(\n",
    "    columns=[c for c in TARGET_COLS if c in numeric_cols]\n",
    "    + [c for c in POST_RELEASE if c in numeric_cols],\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "y = df[TARGET_COLS].copy()\n",
    "\n",
    "# Final cleanup in case of infs\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Log-transform targets (helps on heavy-tailed counts/revenue)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754c6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== Outlier handling: Feature winsorization (train-fit, apply to both) =====\n",
    "# def is_binary(col: pd.Series) -> bool:\n",
    "#     u = pd.unique(col.dropna())\n",
    "#     if len(u) <= 2:\n",
    "#         s = set(u.tolist())\n",
    "#         return s.issubset({0, 1})\n",
    "#     return False\n",
    "\n",
    "# def compute_caps(df: pd.DataFrame, lower_q=0.01, upper_q=0.99):\n",
    "#     \"\"\"Return per-column (lo, hi) quantile caps for non-binary numeric columns.\"\"\"\n",
    "#     caps = {}\n",
    "#     for c in df.columns:\n",
    "#         if np.issubdtype(df[c].dtype, np.number) and not is_binary(df[c]):\n",
    "#             lo = df[c].quantile(lower_q)\n",
    "#             hi = df[c].quantile(upper_q)\n",
    "#             if pd.notnull(lo) and pd.notnull(hi) and lo < hi:\n",
    "#                 caps[c] = (float(lo), float(hi))\n",
    "#     return caps\n",
    "\n",
    "# def apply_caps(df: pd.DataFrame, caps: dict) -> pd.DataFrame:\n",
    "#     df2 = df.copy()\n",
    "#     for c, (lo, hi) in caps.items():\n",
    "#         if c in df2.columns:\n",
    "#             df2[c] = df2[c].clip(lower=lo, upper=hi)\n",
    "#     return df2\n",
    "\n",
    "# # Keep originals for reporting\n",
    "# _Xtr_before = X_train.copy()\n",
    "# _Xte_before = X_test.copy()\n",
    "\n",
    "# # Fit caps on TRAIN only\n",
    "# feature_caps = compute_caps(_Xtr_before, lower_q=0.01, upper_q=0.99)\n",
    "\n",
    "# # Count how many would be clipped BEFORE applying\n",
    "# clip_report = {}\n",
    "# for c, (lo, hi) in feature_caps.items():\n",
    "#     if c in _Xtr_before:\n",
    "#         tr_low  = (_Xtr_before[c] < lo).sum()\n",
    "#         tr_high = (_Xtr_before[c] > hi).sum()\n",
    "#     else:\n",
    "#         tr_low = tr_high = 0\n",
    "#     if c in _Xte_before:\n",
    "#         te_low  = (_Xte_before[c] < lo).sum()\n",
    "#         te_high = (_Xte_before[c] > hi).sum()\n",
    "#     else:\n",
    "#         te_low = te_high = 0\n",
    "#     clip_report[c] = (lo, hi, int(tr_low), int(tr_high), int(te_low), int(te_high))\n",
    "\n",
    "# # Apply caps\n",
    "# X_train = apply_caps(X_train, feature_caps)\n",
    "# X_test  = apply_caps(X_test,  feature_caps)\n",
    "\n",
    "# # (Optional) logically bounded safety constraint\n",
    "# neg_train_dsr = neg_test_dsr = 0\n",
    "# if 'days_since_release' in X_train.columns:\n",
    "#     neg_train_dsr = (X_train['days_since_release'] < 0).sum()\n",
    "#     neg_test_dsr  = (X_test['days_since_release']  < 0).sum()\n",
    "#     X_train['days_since_release'] = X_train['days_since_release'].clip(lower=0)\n",
    "#     X_test['days_since_release']  = X_test['days_since_release'].clip(lower=0)\n",
    "\n",
    "# # ===== Inspect outlier handling results =====\n",
    "# print(\"\\n[Outlier Handling] Winsorization applied to non-binary numeric features:\")\n",
    "# for c, (lo, hi, tr_low, tr_high, te_low, te_high) in clip_report.items():\n",
    "#     print(f\" - {c:>24s}: cap=({lo:.6g}, {hi:.6g}), \"\n",
    "#           f\"train clipped=({tr_low}+{tr_high}), test clipped=({te_low}+{te_high})\")\n",
    "\n",
    "# if 'days_since_release' in X_train.columns:\n",
    "#     print(\"\\n[Outlier Handling] Safety constraint:\")\n",
    "#     print(f\" - days_since_release clipped to >= 0 \"\n",
    "#           f\"(post-clip negatives still in train={int(neg_train_dsr)}, test={int(neg_test_dsr)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fae78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultiOutput LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 31351, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 6.493952\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 31351, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 6.406776\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 31351, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 6.057794\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 615\n",
      "[LightGBM] [Info] Number of data points in the train set: 31351, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 6.031960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-target metrics:\n",
      "    target         RMSE           MAE       R2\n",
      "    owners 6.336046e+05  63056.830430 0.201356\n",
      "   players 5.222761e+05  46552.737653 0.144419\n",
      "copiesSold 4.532626e+05  38698.174255 0.185481\n",
      "   revenue 5.136580e+06 393680.157435 0.185756\n",
      "\n",
      "Average RÂ²: 0.1792528519085004\n",
      "\n",
      "Per-target metrics (RÂ² in %):\n",
      "    target         RMSE           MAE  R2_%\n",
      "    owners 6.336046e+05  63056.830430 20.14\n",
      "   players 5.222761e+05  46552.737653 14.44\n",
      "copiesSold 4.532626e+05  38698.174255 18.55\n",
      "   revenue 5.136580e+06 393680.157435 18.58\n",
      "\n",
      "Average RÂ² (%): 17.93\n",
      "\n",
      "Top 20 features by average importance:\n",
      "days_since_release         6107.50\n",
      "achievements               4533.75\n",
      "price                      4490.00\n",
      "release_day                3474.50\n",
      "release_month              1902.50\n",
      "publisherClass_encoded     1078.00\n",
      "Casual                     1000.50\n",
      "Action                      911.00\n",
      "Adventure                   903.75\n",
      "Indie                       881.25\n",
      "Simulation                  865.00\n",
      "Steam_Cloud                 726.50\n",
      "RPG                         701.00\n",
      "Full_controller_support     644.75\n",
      "mac                         643.25\n",
      "Strategy                    600.00\n",
      "Steam_Achievements          571.50\n",
      "Online_Co_op                552.00\n",
      "linux                       518.75\n",
      "english                     512.50\n",
      "\n",
      "Saved model + meta to: ./artifacts\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Model: LightGBM + MultiOutput\n",
    "# ---------------------------------------------------------------------\n",
    "lgb_params = dict(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=600,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=63,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    ")\n",
    "\n",
    "base_lgb = lgb.LGBMRegressor(**lgb_params)\n",
    "lgb_model = MultiOutputRegressor(base_lgb)\n",
    "\n",
    "print(\"Training MultiOutput LightGBM...\")\n",
    "lgb_model.fit(X_train.values, y_train_log.values)\n",
    "\n",
    "# Predict & invert log\n",
    "y_pred_log = lgb_model.predict(X_test.values)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_true = np.expm1(y_test_log.values)\n",
    "\n",
    "# Metrics\n",
    "metrics_df = evaluate_predictions(y_true, y_pred, TARGET_COLS)\n",
    "print(\"\\nPer-target metrics:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"\\nAverage RÂ²:\", metrics_df[\"R2\"].mean())\n",
    "\n",
    "# RÂ² in %\n",
    "metrics_df_pct = metrics_df.copy()\n",
    "metrics_df_pct[\"R2_%\"] = (metrics_df_pct[\"R2\"] * 100).round(2)\n",
    "print(\"\\nPer-target metrics (RÂ² in %):\")\n",
    "print(metrics_df_pct[[\"target\", \"RMSE\", \"MAE\", \"R2_%\"]].to_string(index=False))\n",
    "print(\"\\nAverage RÂ² (%):\", round(metrics_df_pct[\"R2_%\"].mean(), 2))\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Feature Importance (averaged across targets)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    importances = []\n",
    "    for est in lgb_model.estimators_:\n",
    "        importances.append(est.feature_importances_)\n",
    "    importances = np.vstack(importances)\n",
    "    avg_importance = importances.mean(axis=0)\n",
    "    fi = pd.Series(avg_importance, index=X_train.columns).sort_values(ascending=False)\n",
    "    print(\"\\nTop 20 features by average importance:\")\n",
    "    print(fi.head(20).to_string())\n",
    "except Exception as e:\n",
    "    print(\"Feature importance not available:\", e)\n",
    "\n",
    "# Save\n",
    "joblib.dump(lgb_model, os.path.join(ARTIFACT_DIR, \"lgb_model.pkl\"))\n",
    "joblib.dump(\n",
    "    {\"feature_order\": X_train.columns.tolist(), \"lgb_params\": lgb_params},\n",
    "    os.path.join(ARTIFACT_DIR, \"lgb_model_meta.pkl\"),\n",
    ")\n",
    "print(\"\\nSaved model + meta to:\", ARTIFACT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cac294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultiOutput XGBoost (baseline)...\n",
      "\n",
      "[XGBoost] Per-target metrics:\n",
      "    target         RMSE           MAE        R2\n",
      "    owners 6.888263e+05  66610.942076  0.056078\n",
      "   players 5.633629e+05  49094.654984  0.004509\n",
      "copiesSold 5.036946e+05  42459.389821 -0.005856\n",
      "   revenue 7.624402e+06 451296.845311 -0.793983\n",
      "\n",
      "[XGBoost] Average RÂ²: -0.18481299772229737\n",
      "\n",
      "[XGBoost] Per-target metrics (RÂ² in %):\n",
      "    target         RMSE           MAE   R2_%\n",
      "    owners 6.888263e+05  66610.942076   5.61\n",
      "   players 5.633629e+05  49094.654984   0.45\n",
      "copiesSold 5.036946e+05  42459.389821  -0.59\n",
      "   revenue 7.624402e+06 451296.845311 -79.40\n",
      "\n",
      "[XGBoost] Average RÂ² (%): -18.48\n",
      "\n",
      "[XGBoost] Top 20 features by average importance:\n",
      "is_free                   0.309149\n",
      "publisherClass_encoded    0.219722\n",
      "Family_Sharing            0.120056\n",
      "Steam_Trading_Cards       0.091796\n",
      "price                     0.032425\n",
      "Online_Co_op              0.018815\n",
      "achievements              0.015663\n",
      "Free_To_Play              0.015631\n",
      "Online_PvP                0.011555\n",
      "Multi_player              0.011032\n",
      "Steam_Cloud               0.010034\n",
      "Simulation                0.008924\n",
      "Indie                     0.007281\n",
      "Steam_Achievements        0.007099\n",
      "Casual                    0.006989\n",
      "RPG                       0.006876\n",
      "required_age              0.006017\n",
      "Shared_Split_Screen       0.005766\n",
      "days_since_release        0.005481\n",
      "VR_Only                   0.005304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./artifacts\\\\xgb_params_base.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Model: XGBoost + MultiOutput (baseline)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(\"xgboost is not installed. Run: pip install xgboost\") from e\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    tree_method=\"hist\",\n",
    "    nthread=-1,\n",
    ")\n",
    "\n",
    "xgb_base = xgb.XGBRegressor(**xgb_params)\n",
    "xgb_model = MultiOutputRegressor(xgb_base)\n",
    "\n",
    "print(\"\\nTraining MultiOutput XGBoost (baseline)...\")\n",
    "xgb_model.fit(X_train.values, y_train_log.values)\n",
    "\n",
    "# Predict & invert log\n",
    "xgb_pred_log = xgb_model.predict(X_test.values)\n",
    "xgb_pred = np.expm1(xgb_pred_log)\n",
    "xgb_true = np.expm1(y_test_log.values)\n",
    "\n",
    "# Metrics\n",
    "xgb_metrics = evaluate_predictions(xgb_true, xgb_pred, TARGET_COLS)\n",
    "print(\"\\n[XGBoost] Per-target metrics:\")\n",
    "print(xgb_metrics.to_string(index=False))\n",
    "print(\"\\n[XGBoost] Average RÂ²:\", xgb_metrics[\"R2\"].mean())\n",
    "\n",
    "# RÂ² in %\n",
    "xgb_metrics_pct = xgb_metrics.copy()\n",
    "xgb_metrics_pct[\"R2_%\"] = (xgb_metrics_pct[\"R2\"] * 100).round(2)\n",
    "print(\"\\n[XGBoost] Per-target metrics (RÂ² in %):\")\n",
    "print(xgb_metrics_pct[[\"target\", \"RMSE\", \"MAE\", \"R2_%\"]].to_string(index=False))\n",
    "print(\"\\n[XGBoost] Average RÂ² (%):\", round(xgb_metrics_pct[\"R2_%\"].mean(), 2))\n",
    "\n",
    "# Optional: feature importance (avg across outputs)\n",
    "try:\n",
    "    imps = np.vstack([est.feature_importances_ for est in xgb_model.estimators_])\n",
    "    fi_avg = imps.mean(axis=0)\n",
    "    fi_xgb = pd.Series(fi_avg, index=X_train.columns).sort_values(ascending=False)\n",
    "    print(\"\\n[XGBoost] Top 20 features by average importance:\")\n",
    "    print(fi_xgb.head(20).to_string())\n",
    "except Exception as e:\n",
    "    print(\"XGBoost feature importance not available:\", e)\n",
    "\n",
    "# Save\n",
    "joblib.dump(xgb_model, os.path.join(ARTIFACT_DIR, \"xgb_model.pkl\"))\n",
    "joblib.dump({\"xgb_params\": xgb_params}, os.path.join(ARTIFACT_DIR, \"xgb_params_base.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd17883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MultiOutput CatBoost (baseline)...\n",
      "\n",
      "[CatBoost] Per-target metrics:\n",
      "    target         RMSE           MAE       R2\n",
      "    owners 6.493415e+05  65354.760083 0.161191\n",
      "   players 5.400553e+05  47822.017634 0.085176\n",
      "copiesSold 4.685344e+05  39927.846956 0.129669\n",
      "   revenue 5.018579e+06 389178.421713 0.222737\n",
      "\n",
      "[CatBoost] Average RÂ²: 0.14969343070685762\n",
      "\n",
      "[CatBoost] Per-target metrics (RÂ² in %):\n",
      "    target         RMSE           MAE  R2_%\n",
      "    owners 6.493415e+05  65354.760083 16.12\n",
      "   players 5.400553e+05  47822.017634  8.52\n",
      "copiesSold 4.685344e+05  39927.846956 12.97\n",
      "   revenue 5.018579e+06 389178.421713 22.27\n",
      "\n",
      "[CatBoost] Average RÂ² (%): 14.97\n",
      "\n",
      "[CatBoost] Top 20 features by average importance:\n",
      "publisherClass_encoded    26.036092\n",
      "price                     14.841283\n",
      "Family_Sharing             9.737297\n",
      "achievements               8.328099\n",
      "days_since_release         4.367805\n",
      "is_free                    4.075334\n",
      "Steam_Trading_Cards        2.969327\n",
      "release_day                2.495467\n",
      "Indie                      1.805635\n",
      "Simulation                 1.793689\n",
      "Steam_Cloud                1.685948\n",
      "release_month              1.566475\n",
      "Casual                     1.532546\n",
      "Adventure                  1.398083\n",
      "Online_Co_op               1.368192\n",
      "Free_To_Play               1.348290\n",
      "RPG                        1.335857\n",
      "Action                     1.236711\n",
      "Steam_Achievements         1.181430\n",
      "release_year               1.160550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./artifacts\\\\catboost_params_base.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Model: CatBoost + MultiOutput (baseline)\n",
    "# ---------------------------------------------------------------------\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "except ImportError as e:\n",
    "    raise RuntimeError(\"catboost is not installed. Run: pip install catboost\") from e\n",
    "\n",
    "cb_params = dict(\n",
    "    loss_function=\"RMSE\",\n",
    "    random_seed=42,\n",
    "    n_estimators=1200,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3.0,\n",
    "    subsample=0.8,\n",
    "    verbose=0,\n",
    "    thread_count=-1\n",
    ")\n",
    "\n",
    "cb_base = CatBoostRegressor(**cb_params)\n",
    "cb_model = MultiOutputRegressor(cb_base)\n",
    "\n",
    "print(\"\\nTraining MultiOutput CatBoost (baseline)...\")\n",
    "cb_model.fit(X_train.values, y_train_log.values)\n",
    "\n",
    "# Predict & invert log\n",
    "cb_pred_log = cb_model.predict(X_test.values)\n",
    "cb_pred = np.expm1(cb_pred_log)\n",
    "cb_true = np.expm1(y_test_log.values)\n",
    "\n",
    "# Metrics\n",
    "cb_metrics = evaluate_predictions(cb_true, cb_pred, TARGET_COLS)\n",
    "print(\"\\n[CatBoost] Per-target metrics:\")\n",
    "print(cb_metrics.to_string(index=False))\n",
    "print(\"\\n[CatBoost] Average RÂ²:\", cb_metrics[\"R2\"].mean())\n",
    "\n",
    "# RÂ² in %\n",
    "cb_metrics_pct = cb_metrics.copy()\n",
    "cb_metrics_pct[\"R2_%\"] = (cb_metrics_pct[\"R2\"] * 100).round(2)\n",
    "print(\"\\n[CatBoost] Per-target metrics (RÂ² in %):\")\n",
    "print(cb_metrics_pct[[\"target\", \"RMSE\", \"MAE\", \"R2_%\"]].to_string(index=False))\n",
    "print(\"\\n[CatBoost] Average RÂ² (%):\", round(cb_metrics_pct[\"R2_%\"].mean(), 2))\n",
    "\n",
    "# Optional: feature importance (avg across outputs)\n",
    "try:\n",
    "    imps = np.vstack([est.get_feature_importance() for est in cb_model.estimators_])\n",
    "    fi_avg = imps.mean(axis=0)\n",
    "    fi_cb = pd.Series(fi_avg, index=X_train.columns).sort_values(ascending=False)\n",
    "    print(\"\\n[CatBoost] Top 20 features by average importance:\")\n",
    "    print(fi_cb.head(20).to_string())\n",
    "except Exception as e:\n",
    "    print(\"CatBoost feature importance not available:\", e)\n",
    "\n",
    "# Save\n",
    "joblib.dump(cb_model, os.path.join(ARTIFACT_DIR, \"cb_model.pkl\"))\n",
    "joblib.dump({\"cb_params\": cb_params}, os.path.join(ARTIFACT_DIR, \"catboost_params_base.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e178b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Loss Plot\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "#     X_train, y_train_log, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# cb_base_params = dict(\n",
    "#     loss_function=\"RMSE\",\n",
    "#     random_seed=42,\n",
    "#     n_estimators=1200,\n",
    "#     learning_rate=0.03,\n",
    "#     depth=8,\n",
    "#     l2_leaf_reg=3.0,\n",
    "#     subsample=0.8,\n",
    "#     rsm=0.8,\n",
    "#     verbose=0,\n",
    "#     od_type=\"Iter\",   # enable overfitting detector\n",
    "#     od_wait=100,\n",
    "#     use_best_model=True\n",
    "# )\n",
    "\n",
    "# models = {}\n",
    "# evals_results = {}\n",
    "\n",
    "# for t in TARGET_COLS:\n",
    "#     m = CatBoostRegressor(**cb_base_params)\n",
    "#     m.fit(\n",
    "#         X_tr, y_tr[t],\n",
    "#         eval_set=(X_val, y_val[t]),\n",
    "#         verbose=100  # prints progress every 100 iters\n",
    "#     )\n",
    "#     models[t] = m\n",
    "#     evals_results[t] = m.get_evals_result()  # {'learn':{'RMSE':[...]}, 'validation':{'RMSE':[...]}}\n",
    "\n",
    "# # Plot curves\n",
    "# for t in TARGET_COLS:\n",
    "#     learn_rmse = evals_results[t]['learn']['RMSE']\n",
    "#     val_rmse   = evals_results[t]['validation']['RMSE']\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(learn_rmse, label='train RMSE')\n",
    "#     plt.plot(val_rmse, label='val RMSE')\n",
    "#     plt.title(f'CatBoost learning curves â€” {t} (log1p scale)')\n",
    "#     plt.xlabel('Iteration')\n",
    "#     plt.ylabel('RMSE')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4983dd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------------\n",
    "# # Per-target CatBoost (tune REVENUE only, train all targets separately)\n",
    "# # ---------------------------------------------------------------------\n",
    "# try:\n",
    "#     from catboost import CatBoostRegressor\n",
    "# except ImportError as e:\n",
    "#     raise RuntimeError(\"catboost is not installed. Run: pip install catboost\") from e\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Baseline params for non-revenue targets (same spirit as your baseline)\n",
    "# cb_base_params = dict(\n",
    "#     loss_function=\"RMSE\",\n",
    "#     random_seed=42,\n",
    "#     n_estimators=1200,\n",
    "#     learning_rate=0.03,\n",
    "#     depth=8,\n",
    "#     l2_leaf_reg=3.0,\n",
    "#     subsample=0.8,\n",
    "#     rsm=0.8,          \n",
    "#     verbose=0,\n",
    "#     thread_count=-1,\n",
    "#     od_type=\"Iter\",\n",
    "#     od_wait=100\n",
    "# )\n",
    "\n",
    "# # Search space for revenue tuning (log-space target)\n",
    "# rev_param_dist = {\n",
    "#     \"n_estimators\":     [1200, 1600, 2000, 3000],\n",
    "#     \"learning_rate\":    [0.01, 0.02, 0.03, 0.06],\n",
    "#     \"depth\":            [6, 8, 10],\n",
    "#     \"l2_leaf_reg\":      [1.0, 3.0, 5.0, 7.0, 9.0],\n",
    "#     \"subsample\":        [0.7, 0.8, 1.0],\n",
    "#     \"rsm\":              [0.7, 0.8, 1.0],\n",
    "#     \"random_strength\":  [0.0, 0.5, 1.0, 2.0],\n",
    "#     \"min_data_in_leaf\": [1, 5, 20, 50],\n",
    "# }\n",
    "\n",
    "# print(\"\\n[Tune] CatBoost for 'revenue' (log-space) ...\")\n",
    "# cb_rev_base = CatBoostRegressor(**cb_base_params)\n",
    "\n",
    "# rev_tuner = RandomizedSearchCV(\n",
    "#     estimator=cb_rev_base,\n",
    "#     param_distributions=rev_param_dist,\n",
    "#     n_iter=30,                          \n",
    "#     scoring=\"neg_root_mean_squared_error\",\n",
    "#     cv=3,\n",
    "#     verbose=1,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "\n",
    "# rev_tuner.fit(X_train, y_train_log[\"revenue\"])\n",
    "# cb_rev_best = rev_tuner.best_params_\n",
    "# print(\"Best params for revenue:\", cb_rev_best)\n",
    "\n",
    "# # Build per-target estimators (revenue uses tuned params)\n",
    "# print(\"\\n[Train] Per-target CatBoost models ...\")\n",
    "# cb_models_by_target = {}\n",
    "# for t in TARGET_COLS:\n",
    "#     if t == \"revenue\":\n",
    "#         est = CatBoostRegressor(**{**cb_base_params, **cb_rev_best})\n",
    "#     else:\n",
    "#         est = CatBoostRegressor(**cb_base_params)\n",
    "#     est.fit(X_train, y_train_log[t])\n",
    "#     cb_models_by_target[t] = est\n",
    "\n",
    "# # Predict all targets (stack per-target preds) & invert log\n",
    "# cb_pt_pred_log = np.column_stack([cb_models_by_target[t].predict(X_test) for t in TARGET_COLS])\n",
    "# cb_pt_pred = np.expm1(cb_pt_pred_log)\n",
    "# cb_pt_true = np.expm1(y_test_log.values)\n",
    "\n",
    "# # Metrics\n",
    "# cb_pt_metrics = evaluate_predictions(cb_pt_true, cb_pt_pred, TARGET_COLS)\n",
    "# print(\"\\n[Per-target CatBoost] Per-target metrics (raw):\")\n",
    "# print(cb_pt_metrics.to_string(index=False))\n",
    "# print(\"\\n[Per-target CatBoost] Average RÂ²:\", cb_pt_metrics[\"R2\"].mean())\n",
    "\n",
    "# cb_pt_metrics_pct = cb_pt_metrics.copy()\n",
    "# cb_pt_metrics_pct[\"R2_%\"] = (cb_pt_metrics_pct[\"R2\"] * 100).round(2)\n",
    "# print(\"\\n[Per-target CatBoost] Per-target metrics (RÂ² in %):\")\n",
    "# print(cb_pt_metrics_pct[[\"target\", \"RMSE\", \"MAE\", \"R2_%\"]].to_string(index=False))\n",
    "# print(\"\\n[Per-target CatBoost] Average RÂ² (%):\", round(cb_pt_metrics_pct[\"R2_%\"].mean(), 2))\n",
    "\n",
    "# # Save artifacts\n",
    "# joblib.dump(cb_models_by_target, os.path.join(ARTIFACT_DIR, \"catboost_per_target_models.pkl\"))\n",
    "# joblib.dump(cb_rev_best, os.path.join(ARTIFACT_DIR, \"catboost_revenue_best_params.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b20fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------------------------------\n",
    "# # Save artifact\n",
    "# # ---------------------------------------------------------------------\n",
    "# joblib.dump(model, os.path.join(ARTIFACT_DIR, \"lgb_multioutput.pkl\"))\n",
    "# joblib.dump({\"feature_order\": X_train.columns.tolist(), \"lgb_params\": lgb_params}, os.path.join(ARTIFACT_DIR, \"model_meta.pkl\"))\n",
    "# print(\"\\nSaved model + meta to:\", ARTIFACT_DIR)\n",
    "\n",
    "# # ---------------------------------------------------------------------\n",
    "# # Helper: Predict up to a planned EXTRACT date (for dev UI)\n",
    "# # ---------------------------------------------------------------------\n",
    "# def predict_until_deadline(input_row: dict, feature_order=None):\n",
    "#     \"\"\"\n",
    "#     input_row: dict containing the same pre-release fields used in X (numeric only),\n",
    "#                plus the required date parts:\n",
    "#                'release_year','release_month','release_day','extract_year','extract_month','extract_day'\n",
    "#     NOTE: Do NOT include POST_RELEASE fields; this simulates pre-release planning.\n",
    "\n",
    "#     Returns: dict with predictions for the 4 targets.\n",
    "#     \"\"\"\n",
    "#     # Build a 1-row DataFrame\n",
    "#     xr = pd.DataFrame([input_row]).copy()\n",
    "\n",
    "#     # Build days_since_release from parts\n",
    "#     if not {'release_year','release_month','release_day','extract_year','extract_month','extract_day'}.issubset(xr.columns):\n",
    "#         raise ValueError(\"Missing release_* or extract_* date parts in input_row.\")\n",
    "#     rel = pd.to_datetime(dict(\n",
    "#         year=xr['release_year'].astype(int),\n",
    "#         month=xr['release_month'].astype(int),\n",
    "#         day=xr['release_day'].astype(int)\n",
    "#     ), errors='coerce')\n",
    "#     ext = pd.to_datetime(dict(\n",
    "#         year=xr['extract_year'].astype(int),\n",
    "#         month=xr['extract_month'].astype(int),\n",
    "#         day=xr['extract_day'].astype(int)\n",
    "#     ), errors='coerce')\n",
    "#     xr['days_since_release'] = (ext - rel).dt.days\n",
    "\n",
    "#     # Basic engineered features (same as training)\n",
    "#     if 'price' in xr.columns and 'achievements' in xr.columns:\n",
    "#         xr['price_per_achievement'] = xr['price'] / (xr['achievements'] + 1)\n",
    "#     if 'wishlists' in xr.columns and 'days_since_release' in xr.columns:\n",
    "#         xr['wishlists_per_day'] = xr['wishlists'] / (xr['days_since_release'] + 1)\n",
    "#     if 'price' in xr.columns and 'days_since_release' in xr.columns:\n",
    "#         xr['price_x_age'] = xr['price'] * np.log1p(xr['days_since_release'])\n",
    "\n",
    "#     # Convert bools to ints\n",
    "#     for c in xr.columns:\n",
    "#         if xr[c].dtype == bool:\n",
    "#             xr[c] = xr[c].astype(int)\n",
    "\n",
    "#     # Keep numeric only & drop post-release leakage\n",
    "#     numeric_cols = xr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "#     xr_num = xr[numeric_cols].drop(columns=[c for c in POST_RELEASE if c in numeric_cols], errors='ignore')\n",
    "\n",
    "#     # Reindex to training feature order (missing cols -> 0, extras dropped)\n",
    "#     if feature_order is None:\n",
    "#         feature_order = X_train.columns.tolist()\n",
    "#     xr_num = xr_num.reindex(columns=feature_order, fill_value=0.0)\n",
    "\n",
    "#     pred_log = model.predict(xr_num.values)\n",
    "#     pred = np.expm1(pred_log)[0]\n",
    "#     return dict(zip(TARGET_COLS, pred.astype(float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde4e940",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6a7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for prediction:\n",
      " - price\n",
      " - is_free\n",
      " - release_year\n",
      " - release_month\n",
      " - release_day\n",
      " - extract_year\n",
      " - extract_month\n",
      " - extract_day\n",
      " - publisherClass_encoded\n",
      " - required_age\n",
      " - achievements\n",
      " - english\n",
      " - windows\n",
      " - mac\n",
      " - linux\n",
      " - Single_player\n",
      " - Family_Sharing\n",
      " - Steam_Achievements\n",
      " - Steam_Cloud\n",
      " - Full_controller_support\n",
      " - Multi_player\n",
      " - Partial_Controller_Support\n",
      " - Steam_Trading_Cards\n",
      " - PvP\n",
      " - Co_op\n",
      " - Steam_Leaderboards\n",
      " - Remote_Play_Together\n",
      " - Online_PvP\n",
      " - Shared_Split_Screen\n",
      " - Tracked_Controller_Support\n",
      " - VR_Only\n",
      " - Shared_Split_Screen_PvP\n",
      " - Online_Co_op\n",
      " - Stats\n",
      " - Shared_Split_Screen_Co_op\n",
      " - Indie\n",
      " - Casual\n",
      " - Adventure\n",
      " - Action\n",
      " - Simulation\n",
      " - Strategy\n",
      " - RPG\n",
      " - Free_To_Play\n",
      " - Sports\n",
      " - Racing\n",
      " - days_since_release\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artifacts\\\\features_used.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_used = X_train.columns.tolist()\n",
    "\n",
    "print(\"Features used for prediction:\")\n",
    "for feature in features_used:\n",
    "    print(f\" - {feature}\")\n",
    "\n",
    "features_array = np.array(features_used)\n",
    "joblib.dump(np.array(features_used), Path(ARTIFACT_DIR) / \"features_used.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "515df75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_game_success(user_input: dict, model, features_used: list):\n",
    "    \"\"\"\n",
    "    Predict success metrics for a new game based on user input.\n",
    "\n",
    "    Parameters:\n",
    "        user_input (dict): Raw user inputs.\n",
    "        model: Trained MultiOutputRegressor model.\n",
    "        features_used (list): List of feature column names used in training.\n",
    "    \"\"\"\n",
    "    # 1. Base dictionary with all 0s\n",
    "    input_data = {feature: 0 for feature in features_used}\n",
    "\n",
    "    # 2. Basic direct inputs\n",
    "    input_data['price'] = user_input.get('price', 0)\n",
    "    input_data['is_free'] = int(user_input.get('is_free', False))\n",
    "    input_data['required_age'] = user_input.get('required_age', 0)\n",
    "    input_data['achievements'] = user_input.get('achievements', 0)\n",
    "    input_data['english'] = int(user_input.get('english', True))\n",
    "\n",
    "    # 3. Platform & features flags\n",
    "    platform_flags = ['windows', 'mac', 'linux']\n",
    "    tag_flags = [\n",
    "        'Single-player', 'Family Sharing', 'Steam Achievements', 'Steam Cloud',\n",
    "        'Full controller support', 'Multi-player', 'Partial Controller Support',\n",
    "        'Steam Trading Cards', 'PvP', 'Co-op', 'Steam Leaderboards', 'Remote Play Together',\n",
    "        'Online PvP', 'Shared/Split Screen', 'Tracked Controller Support', 'VR Only',\n",
    "        'Shared/Split Screen PvP', 'Online Co-op', 'Stats', 'Shared/Split Screen Co-op'\n",
    "    ]\n",
    "    genre_flags = ['Indie', 'Casual', 'Adventure', 'Action', 'Simulation',\n",
    "                   'Strategy', 'RPG', 'Free To Play', 'Sports', 'Racing']\n",
    "\n",
    "    for flag in platform_flags + tag_flags + genre_flags:\n",
    "        input_data[flag] = int(user_input.get(flag, False))\n",
    "\n",
    "    # 4. Publisher Class (encoded) â€” still numeric\n",
    "    input_data['publisherClass_encoded'] = user_input.get('publisherClass_encoded', 0)\n",
    "\n",
    "    # 5. Days Since Release\n",
    "    release_date = pd.to_datetime(user_input['release_date'])\n",
    "    extract_date = pd.to_datetime(user_input['extract_date'])\n",
    "    input_data['days_since_release'] = (extract_date - release_date).days\n",
    "\n",
    "    # Convert to DataFrame with correct feature order\n",
    "    input_df = pd.DataFrame([input_data])[features_used]\n",
    "\n",
    "    # Predict (trained on log-transformed targets)\n",
    "    y_pred_log = model.predict(input_df)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    return {\n",
    "        'owners': int(y_pred[0][0]),\n",
    "        'players': int(y_pred[0][1]),\n",
    "        'copiesSold': int(y_pred[0][2]),\n",
    "        'revenue': float(y_pred[0][3])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7720d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_input_format(df, steamid=None, row_num=None):\n",
    "    if steamid is not None:\n",
    "        game = df[df[\"steamid\"] == steamid]\n",
    "        if game.empty:\n",
    "            raise ValueError(f\"No game found with steamid {steamid}\")\n",
    "        game = game.iloc[0]\n",
    "    elif row_num is not None:\n",
    "        game = df.iloc[row_num]\n",
    "    else:\n",
    "        raise ValueError(\"You must provide either a steamid or a row_num.\")\n",
    "\n",
    "    release_date = f\"{int(game['release_year'])}-{int(game['release_month']):02d}-{int(game['release_day']):02d}\"\n",
    "    extract_date = f\"{int(game['extract_year'])}-{int(game['extract_month']):02d}-{int(game['extract_day']):02d}\"\n",
    "\n",
    "    input_data = {\n",
    "        \"price\": float(game[\"price\"]),\n",
    "        \"is_free\": bool(game[\"is_free\"]),\n",
    "        \"required_age\": int(game[\"required_age\"]),\n",
    "        \"achievements\": int(game[\"achievements\"]),\n",
    "        \"english\": bool(game[\"english\"]),\n",
    "        \"windows\": bool(game[\"windows\"]),\n",
    "        \"mac\": bool(game[\"mac\"]),\n",
    "        \"linux\": bool(game[\"linux\"]),\n",
    "        \"release_date\": release_date,\n",
    "        \"extract_date\": extract_date,\n",
    "        \"publisherClass_encoded\": int(game[\"publisherClass_encoded\"]),\n",
    "    }\n",
    "\n",
    "    # Add boolean flags\n",
    "    boolean_cols = game.index[\n",
    "        game.index.isin([\n",
    "            \"Single-player\",\"Family Sharing\",\"Steam Achievements\",\"Steam Cloud\",\n",
    "            \"Full controller support\",\"Multi-player\",\"Partial Controller Support\",\n",
    "            \"Steam Trading Cards\",\"PvP\",\"Co-op\",\"Steam Leaderboards\",\"Remote Play Together\",\n",
    "            \"Online PvP\",\"Shared/Split Screen\",\"Tracked Controller Support\",\"VR Only\",\n",
    "            \"Shared/Split Screen PvP\",\"Online Co-op\",\"Stats\",\"Shared/Split Screen Co-op\",\n",
    "            \"Indie\",\"Casual\",\"Adventure\",\"Action\",\"Simulation\",\"Strategy\",\"RPG\",\n",
    "            \"Free To Play\",\"Sports\",\"Racing\"\n",
    "        ])\n",
    "    ]\n",
    "    for col in boolean_cols:\n",
    "        input_data[col] = bool(game[col])\n",
    "\n",
    "    # Extract targets for comparison\n",
    "    players = game[\"players\"]\n",
    "    owners = game[\"owners\"]\n",
    "    copies_sold = game[\"copiesSold\"]\n",
    "    revenue = game[\"revenue\"]\n",
    "    wishlists = game[\"wishlists\"]\n",
    "    avg_playtime = game[\"avgPlaytime\"]\n",
    "    followers = game[\"followers\"]\n",
    "    reviews = game[\"reviews\"]\n",
    "    review_score = game[\"reviewScore\"]\n",
    "\n",
    "    return (\n",
    "        input_data,\n",
    "        players,\n",
    "        owners,\n",
    "        copies_sold,\n",
    "        revenue,\n",
    "        wishlists,\n",
    "        avg_playtime,\n",
    "        followers,\n",
    "        reviews,\n",
    "        review_score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b9af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- universal input builder (keeps your behavior) ---\n",
    "# def _build_input_df(user_input: dict, features_used: list) -> pd.DataFrame:\n",
    "#     # start with zeros for every training feature\n",
    "#     input_data = {feature: 0 for feature in features_used}\n",
    "\n",
    "#     # basics\n",
    "#     input_data['price'] = user_input.get('price', 0)\n",
    "#     input_data['is_free'] = int(user_input.get('is_free', False))\n",
    "#     input_data['required_age'] = user_input.get('required_age', 0)\n",
    "#     input_data['achievements'] = user_input.get('achievements', 0)\n",
    "#     input_data['english'] = int(user_input.get('english', True))\n",
    "\n",
    "#     # platform/tags/genres\n",
    "#     platform_flags = ['windows', 'mac', 'linux']\n",
    "#     tag_flags = [\n",
    "#         'Single-player','Family Sharing','Steam Achievements','Steam Cloud',\n",
    "#         'Full controller support','Multi-player','Partial Controller Support',\n",
    "#         'Steam Trading Cards','PvP','Co-op','Steam Leaderboards','Remote Play Together',\n",
    "#         'Online PvP','Shared/Split Screen','Tracked Controller Support','VR Only',\n",
    "#         'Shared/Split Screen PvP','Online Co-op','Stats','Shared/Split Screen Co-op'\n",
    "#     ]\n",
    "#     genre_flags = ['Indie','Casual','Adventure','Action','Simulation',\n",
    "#                    'Strategy','RPG','Free To Play','Sports','Racing']\n",
    "#     for flag in platform_flags + tag_flags + genre_flags:\n",
    "#         input_data[flag] = int(user_input.get(flag, False))\n",
    "\n",
    "#     # numeric class encoding (if present)\n",
    "#     input_data['publisherClass_encoded'] = user_input.get('publisherClass_encoded', 0)\n",
    "\n",
    "#     # days_since_release from user-provided dates\n",
    "#     release_date = pd.to_datetime(user_input['release_date'])\n",
    "#     extract_date = pd.to_datetime(user_input['extract_date'])\n",
    "#     input_data['days_since_release'] = (extract_date - release_date).days\n",
    "\n",
    "#     # build 1-row DF in training feature order\n",
    "#     return pd.DataFrame([input_data])[features_used]\n",
    "\n",
    "\n",
    "# # --- predict with MultiOutputRegressor OR per-target dict ---\n",
    "# def predict_game_success(user_input: dict, estimator, features_used: list,\n",
    "#                          target_cols=('owners','players','copiesSold','revenue')):\n",
    "#     \"\"\"\n",
    "#     Works with:\n",
    "#       - MultiOutputRegressor models (e.g., LightGBM, XGBoost, CatBoost baseline)\n",
    "#       - Per-target models dict, e.g. {'owners': est, 'players': est, ...} or {0: est, 1: est, ...}\n",
    "#     All models expected to be trained on log1p(target).\n",
    "#     \"\"\"\n",
    "#     X = _build_input_df(user_input, features_used)\n",
    "\n",
    "#     # Case A: dict of per-target estimators\n",
    "#     if isinstance(estimator, dict):\n",
    "#         preds = {}\n",
    "#         for idx, t in enumerate(target_cols):\n",
    "#             # allow either name or index keys\n",
    "#             est = estimator.get(t, estimator.get(idx))\n",
    "#             if est is None:\n",
    "#                 raise ValueError(f\"No estimator found for target '{t}' (or index {idx}) in models dict.\")\n",
    "#             log_pred = est.predict(X)[0]\n",
    "#             preds[t] = float(np.expm1(log_pred))\n",
    "\n",
    "#         # cast to desired types\n",
    "#         return {\n",
    "#             'owners': int(round(preds['owners'])),\n",
    "#             'players': int(round(preds['players'])),\n",
    "#             'copiesSold': int(round(preds['copiesSold'])),\n",
    "#             'revenue': float(preds['revenue']),\n",
    "#         }\n",
    "\n",
    "#     # Case B: MultiOutputRegressor (or any estimator returning shape (n,4))\n",
    "#     else:\n",
    "#         y_pred_log = estimator.predict(X)\n",
    "#         # Ensure 2D\n",
    "#         y_pred_log = np.atleast_2d(y_pred_log)\n",
    "#         y_pred = np.expm1(y_pred_log)[0]\n",
    "\n",
    "#         return {\n",
    "#             'owners': int(round(y_pred[0])),\n",
    "#             'players': int(round(y_pred[1])),\n",
    "#             'copiesSold': int(round(y_pred[2])),\n",
    "#             'revenue': float(y_pred[3]),\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9424168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aimy\\AppData\\Local\\Temp\\ipykernel_12540\\2700314925.py:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"steam_dataset.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owners: 14,733\n",
      "players: 11,845\n",
      "copiesSold: 9,017\n",
      "revenue: $38,362.87\n",
      "\n",
      "owners: 36,930\n",
      "players: 19,844\n",
      "copiesSold: 12,910\n",
      "revenue: $47,276.65\n",
      "\n",
      "owners: 23,092\n",
      "players: 13,996\n",
      "copiesSold: 10,671\n",
      "revenue: $28,754.22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"steam_dataset.csv\")\n",
    "\n",
    "steamid = 235520\n",
    "#24880\n",
    "#2124490\n",
    "#315210\n",
    "#340020\n",
    "#290100\n",
    "\n",
    "\n",
    "# --- Step 1: Get game input and actual values from dataset\n",
    "(\n",
    "    game_dict,\n",
    "    players,\n",
    "    owners,\n",
    "    copies_sold,\n",
    "    revenue,\n",
    "    wishlists,\n",
    "    avg_playtime,\n",
    "    followers,\n",
    "    reviews,\n",
    "    review_score,\n",
    ") = get_game_input_format(df, steamid=steamid)\n",
    "\n",
    "preds = predict_game_success(\n",
    "    game_dict, lgb_model, features_used\n",
    ")\n",
    "\n",
    "preds2 = predict_game_success(\n",
    "    game_dict, xgb_model, features_used\n",
    ")\n",
    "\n",
    "preds3 = predict_game_success(\n",
    "    game_dict, cb_model, features_used\n",
    ")\n",
    "\n",
    "# print(preds)\n",
    "for k, v in preds.items():\n",
    "    print(f\"{k}: {v:,.0f}\" if k != \"revenue\" else f\"{k}: ${v:,.2f}\\n\")\n",
    "    \n",
    "for k, v in preds2.items():\n",
    "    print(f\"{k}: {v:,.0f}\" if k != \"revenue\" else f\"{k}: ${v:,.2f}\\n\")\n",
    "\n",
    "for k, v in preds3.items():\n",
    "    print(f\"{k}: {v:,.0f}\" if k != \"revenue\" else f\"{k}: ${v:,.2f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19185e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| Metric     | Predicted   | Actual     | Absolute Error   | Percentage Error   | Accuracy   |\n",
      "+============+=============+============+==================+====================+============+\n",
      "| owners     | 14,733      | 27,609.0   | 12,876.0         | 46.64%             | 53.36%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| players    | 11,845      | 15,060.0   | 3,215.0          | 21.35%             | 78.65%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| copiesSold | 9,017       | 11,412.0   | 2,395.0          | 20.99%             | 79.01%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| revenue    | $38,362.87  | $65,992.00 | $27,629.13       | 41.87%             | 58.13%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| owners     | 36,930      | 27,609.0   | 9,321.0          | 33.76%             | 66.24%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| players    | 19,844      | 15,060.0   | 4,784.0          | 31.77%             | 68.23%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| copiesSold | 12,910      | 11,412.0   | 1,498.0          | 13.13%             | 86.87%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| revenue    | $47,276.65  | $65,992.00 | $18,715.35       | 28.36%             | 71.64%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| owners     | 23,092      | 27,609.0   | 4,517.0          | 16.36%             | 83.64%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| players    | 13,996      | 15,060.0   | 1,064.0          | 7.07%              | 92.93%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| copiesSold | 10,671      | 11,412.0   | 741.0            | 6.49%              | 93.51%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n",
      "| revenue    | $28,754.22  | $65,992.00 | $37,237.78       | 56.43%             | 43.57%     |\n",
      "+------------+-------------+------------+------------------+--------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "actual = {\n",
    "    \"owners\": owners,\n",
    "    \"players\": players,\n",
    "    \"copiesSold\": copies_sold,\n",
    "    \"revenue\": revenue,\n",
    "}\n",
    "\n",
    "# Define headers and rows\n",
    "headers = [\"Metric\", \"Predicted\", \"Actual\", \"Absolute Error\", \"Percentage Error\", \"Accuracy\"]\n",
    "\n",
    "# Build table rows\n",
    "rows = []\n",
    "\n",
    "def print_preds(preds):\n",
    "    for key in preds:\n",
    "        pred_val = preds[key]\n",
    "        actual_val = actual[key]\n",
    "        abs_error = abs(actual_val - pred_val)\n",
    "        pct_error = abs_error / actual_val * 100 if actual_val != 0 else 0\n",
    "        accuracy = 100 - pct_error \n",
    "\n",
    "        if key == \"revenue\":\n",
    "            row = [\n",
    "                key,\n",
    "                f\"${pred_val:,.2f}\",\n",
    "                f\"${actual_val:,.2f}\",\n",
    "                f\"${abs_error:,.2f}\",\n",
    "                f\"{pct_error:.2f}%\",\n",
    "                f\"{accuracy:.2f}%\",\n",
    "            ]\n",
    "        else:\n",
    "            row = [\n",
    "                key,\n",
    "                f\"{pred_val:,}\",\n",
    "                f\"{actual_val:,}\",\n",
    "                f\"{abs_error:,}\",\n",
    "                f\"{pct_error:.2f}%\",\n",
    "                f\"{accuracy:.2f}%\",\n",
    "            ]\n",
    "        rows.append(row)\n",
    "\n",
    "\n",
    "print_preds(preds)\n",
    "print_preds(preds2)\n",
    "print_preds(preds3)\n",
    "print(tabulate.tabulate(rows, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5134cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved game data game_235520.json\n"
     ]
    }
   ],
   "source": [
    "# Save the target game's data to a json file\n",
    "game_row = df[df[\"steamid\"] == steamid].to_dict(orient=\"records\")[0]\n",
    "\n",
    "output = {\n",
    "    \"steamid\": steamid,\n",
    "    \"dataset_entry\": game_row\n",
    "}\n",
    "\n",
    "with open(f\"./jsons/game_{steamid}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved game data game_{steamid}.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
